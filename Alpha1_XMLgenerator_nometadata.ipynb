{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "419a0c98",
   "metadata": {},
   "source": [
    "# Part 4: XML creation\n",
    "## Dependencies: OTIO and pandas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a85b95ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68910a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pyloudnorm as pyln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ecbceef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: CPU random generator seem to be failing, disabling hardware random number generation\n",
      "WARNING: RDRND generated: 0xffffffff 0xffffffff 0xffffffff 0xffffffff\n"
     ]
    }
   ],
   "source": [
    "#video\n",
    "import moviepy\n",
    "from moviepy.editor import *\n",
    "import opentimelineio as otio\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3a7e8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f9bf31",
   "metadata": {},
   "source": [
    "### Quick summary, OTIO can output XML that CAN be used to import timelines. We just need to learn the behavior and then create a loop to automate clipping, using a imported dataframe as a outline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bb2dd9",
   "metadata": {},
   "source": [
    "# Timeline Outline behavior testing\n",
    "- First create a list of videos\n",
    "    - sfs\n",
    "- Sec create list of audio\n",
    "\n",
    "- Link audio to video, IE if mic1 use center camera\n",
    "\n",
    "## Use the lists of camera and audio to createa loops creating timeranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea588d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_VIDEO_TUPLE_LIST=[(\"E2 - Chukwu.mp3\", 1), (\"E2 - Osi.mp3\", 1),(\"E2 - Crystal.mp3\",2),(\"E2 - Scott.mp3\",2)]\n",
    "\n",
    "VIDEO_FILEPATH_LIST= [\"Hang out 2 Middle.mp4\",\"Hang out 2 Left.mp4\",\"Hang out 2 Right.mp4\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03efb571",
   "metadata": {},
   "source": [
    "# Further data editing \n",
    "\n",
    "## Create a camera view column that matches the audio_video_tuple to  idxmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f07ad689",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df=pd.read_pickle('idxmax.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76ba6d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use indexes of when crossover is 1 to change cam_view to 0 for three seconds after crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62f6cb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap = cv2. VideoCapture(VIDEO_FILEPATH_LIST[0])\n",
    "vlength = int(cap. get(cv2. CAP_PROP_FRAME_COUNT))\n",
    "alength=len(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bc36f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103904"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alength\n",
    "vlength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "788196d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vrate=24\n",
    "arate=500\n",
    "arate_actual=24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df113f99",
   "metadata": {},
   "source": [
    "## Create intervals of data in tuple form. \n",
    "\n",
    "## idxmax_mic_data are Video Tuples which  represent the start and end frame of main speaker. Can be used for audio data as well when there is sufficient mic bleed.\n",
    "\n",
    "## threshold_mic_data are Audio Tuples represent the start and end frame of when mic is being used.\n",
    "\n",
    "\n",
    "## Main cam tuples use the main cam column in the dataframe to change to center cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbf64797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_getintervals(series,desiredvalue):\n",
    "    #make sure series is the df['column']\n",
    "    t=series.index[series==desiredvalue].to_series()\n",
    "    interval_list=t.groupby(t.diff().ne(1).cumsum()).agg(['first','last']).apply(tuple,1).tolist()\n",
    "    \n",
    "    return interval_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcb2df49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create lists of tuples for each camera based on the audio\n",
    "\n",
    "list_of_idxmax_mic_data=[]\n",
    "for i in range(len(AUDIO_VIDEO_TUPLE_LIST)+1):\n",
    "    tuple_list=dataframe_getintervals(data_df['idxmax'],i)\n",
    "    list_of_idxmax_mic_data.append(tuple_list)\n",
    "\n",
    "    \n",
    "##create lists of tuples for each Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d80e0dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Audio Tuples\n",
    "#creating a list to referencing the column names of df \n",
    "list_str_audio_thresholds=[]\n",
    "for irow in range(len(AUDIO_VIDEO_TUPLE_LIST)):\n",
    "    varname=\"A\"\n",
    "    list_str_audio_thresholds.append(varname+str(irow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49637034",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create lists of tuples for each audio based the threshold region\n",
    "list_of_tuples_threshold_mic_data=[]\n",
    "for i in range(len(AUDIO_VIDEO_TUPLE_LIST)):\n",
    "    tuple_list=dataframe_getintervals(data_df[list_str_audio_thresholds[i]],1)\n",
    "    list_of_tuples_threshold_mic_data.append(tuple_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52b0fdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main cam tuple list\n",
    "main_cam_tuple_list=dataframe_getintervals(data_df['Main_cam'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99cde904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(main_cam_tuple_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7ec7cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_cam_tuple_list_corrected=[]\n",
    "guard=0\n",
    "count=0\n",
    "for i in range(len(main_cam_tuple_list)):\n",
    "    \n",
    "    if guard==0:\n",
    "        \n",
    "        if i+1==len(main_cam_tuple_list):\n",
    "            pass\n",
    "        else:\n",
    "            if main_cam_tuple_list[i+1][0]-main_cam_tuple_list[i][1]<arate*3:\n",
    "                #create tuple\n",
    "                new_tuple=(main_cam_tuple_list[i][0],main_cam_tuple_list[i+1][1])\n",
    "                #add tuple to list\n",
    "                main_cam_tuple_list_corrected.append(new_tuple)\n",
    "                guard=1\n",
    "\n",
    "            else:\n",
    "                main_cam_tuple_list_corrected.append(main_cam_tuple_list[i])\n",
    "    \n",
    "    else:\n",
    "        guard=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af7b89ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_audio_idxmax_mic_data=[]\n",
    "\n",
    "for i in range(len(list_of_idxmax_mic_data)):\n",
    "#for each list of tuple in the list\n",
    "    new_tuple_list=[]\n",
    "    \n",
    "    for i2 in range(len(list_of_idxmax_mic_data[i])):\n",
    "    #for each element in tuple, add 1.5*rate to \n",
    "        \n",
    "        extended_tuple=(list_of_idxmax_mic_data[i][i2][0]+arate*1.5,list_of_idxmax_mic_data[i][i2][1]+arate*1.5)\n",
    "        \n",
    "        \n",
    "        \n",
    "        new_tuple_list.append(extended_tuple)\n",
    "        \n",
    " \n",
    "    \n",
    "    extended_audio_idxmax_mic_data.append(new_tuple_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1a6a27",
   "metadata": {},
   "source": [
    "extended_audio_idxmax_mic_data_corrected=\n",
    "guard=0\n",
    "count=0\n",
    "    if guard==0:\n",
    "\n",
    "        if i+1==len(list_of_idxmax_mic_data):\n",
    "            pass\n",
    "        else:\n",
    "            if main_cam_tuple_list[i+1][0]-main_cam_tuple_list[i][1]<arate*3:\n",
    "                #create tuple\n",
    "                new_tuple=(main_cam_tuple_list[i][0],main_cam_tuple_list[i+1][1])\n",
    "                #add tuple to list\n",
    "                main_cam_tuple_list_corrected.append(new_tuple)\n",
    "                guard=1\n",
    "\n",
    "            else:\n",
    "                main_cam_tuple_list_corrected.append(main_cam_tuple_list[i])\n",
    "\n",
    "    else:\n",
    "                guard=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55566332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#skeletal outline of otio\n",
    "\n",
    "\n",
    "# build the structure\n",
    "tl = otio.schema.Timeline(name=\"Example timeline\")\n",
    "\n",
    "# add track for each video file and each audio file\n",
    "#for each file add a track\n",
    "\n",
    "#create lists for each track to reference back to later\n",
    "#vtr is video track, etc.\n",
    "vtr_list=[]\n",
    "atr_list=[]\n",
    "\n",
    "\n",
    "#add a audio AND video track for each video track\n",
    "    #default cam first because it is lowest priority\n",
    "vtr_default = otio.schema.Track(name=\"Default_camera\", kind=\"Video\")\n",
    "tl.tracks.append(vtr_default)\n",
    "\n",
    "for i in AUDIO_VIDEO_TUPLE_LIST:\n",
    "    atr = otio.schema.Track(name=i[0], kind=\"Audio\")\n",
    "    tl.tracks.append(atr)\n",
    "    atr_list.append(atr)\n",
    "    \n",
    "    #video\n",
    "    vtr = otio.schema.Track(name=i[0]+\"_video\", kind=\"Video\")\n",
    "    tl.tracks.append(vtr)\n",
    "    vtr_list.append(vtr)\n",
    "\n",
    "# add main cam\n",
    "main_tr = otio.schema.Track(name='Main_Cam')\n",
    "tl.tracks.append(main_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c171267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vrate=24\n",
    "arate=500\n",
    "arate_actual=24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2ec573",
   "metadata": {},
   "source": [
    "# Two different loops, One for Video, another for audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1e12861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#video clips\n",
    "# i is to keep track which audio file we are currently on\n",
    "i=-1\n",
    "\n",
    "# i2 is to keep track of how many clips there are\n",
    "i2=0\n",
    "\n",
    "for lists_of_tuples in list_of_idxmax_mic_data:\n",
    "    #connect the list of tuples to the audio file\n",
    "    #ignore 0 for now. We will come back to this later, i will still be -1 but we will add a default clip instead\n",
    "    \n",
    "    if i==-1:\n",
    "    #add the entire default cam clip in the lowest priority\n",
    "        #vclip\n",
    "        #aclip\n",
    "        pass\n",
    "    \n",
    "    else: \n",
    "        #print(AUDIO_VIDEO_TUPLE_LIST[i],VIDEO_FILEPATH_LIST[AUDIO_VIDEO_TUPLE_LIST[i][1]])\n",
    "    \n",
    "        # Connect the audio and video tracks \n",
    "        atrack=atr_list[i]\n",
    "        afname=AUDIO_VIDEO_TUPLE_LIST[i][0]\n",
    "        \n",
    "        # AUDIO_VIDEO_TUPLE_LIST[i][1] references the VIDEO_FILEPATH_LIST to determine which video file to use\n",
    "        vtrack=vtr_list[i]\n",
    "        vfname=VIDEO_FILEPATH_LIST[AUDIO_VIDEO_TUPLE_LIST[i][1]]\n",
    "        \n",
    "        \n",
    "        \n",
    "        #will remember the previous end of clip's timecode\n",
    "        #will reset to 0 when a video-audio track pair is done\n",
    "        vprevious_end_timecode=0\n",
    "        aprevious_end_timecode=0\n",
    "        \n",
    "    #=========================================================================\n",
    "           \n",
    "        for tuples in lists_of_tuples:\n",
    "            \n",
    "        #=====================================================\n",
    "          #adding variables for time and duration calculation\n",
    "            #Video clips \n",
    "            v_clip_starttime=tuples[0]/arate*vrate\n",
    "            v_clip_duration=tuples[1]/arate*vrate-v_clip_starttime\n",
    "\n",
    "            \n",
    "        #Specifying the start time and end time of the video file where clips come from\n",
    "            v_clip_available_range=otio.opentime.TimeRange(\n",
    "            start_time=otio.opentime.RationalTime(0, vrate),\n",
    "            duration=otio.opentime.RationalTime(vlength, vrate))\n",
    "            \n",
    "            vref = otio.schema.ExternalReference(target_url=vfname,\n",
    "            available_range=v_clip_available_range)\n",
    "            \n",
    "            \n",
    "        #specifying where the start timecode and end timecode of the clip is\n",
    "            v_clip_source_range=otio.opentime.TimeRange(\n",
    "                start_time=otio.opentime.RationalTime(v_clip_starttime, vrate),\n",
    "                duration=otio.opentime.RationalTime(v_clip_duration, vrate))\n",
    "\n",
    "\n",
    "\n",
    "        #Video Gaps\n",
    "            #the gap length is equal to (timecode of next clip time - timecode end of previous clip)\n",
    "            v_gap_start_time=0\n",
    "            v_gap_duration=v_clip_starttime-vprevious_end_timecode\n",
    "            \n",
    "            v_gap_timerange=otio.opentime.TimeRange(\n",
    "                start_time=otio.opentime.RationalTime(v_gap_start_time, vrate),\n",
    "                duration=otio.opentime.RationalTime(v_gap_duration, vrate))\n",
    "            \n",
    "                \n",
    "            \n",
    "            \n",
    "         #=====================================================   \n",
    "            # adding gaps before adding clips\n",
    "            #convert the tuple ranges from audio rate to video rate\n",
    "                #audio rate=500\n",
    "                #video rate=24\n",
    "\n",
    "\n",
    "\n",
    "            # create gap settings\n",
    "            vgap = otio.schema.Gap(\n",
    "                name=\"vGap{}\".format(i2 + 1),\n",
    "\n",
    "                # available_range_from_list is the \n",
    "                source_range=otio.opentime.TimeRange(\n",
    "                    start_time=otio.opentime.RationalTime(\n",
    "                        v_gap_timerange.start_time.value,\n",
    "                        v_gap_timerange.start_time.rate\n",
    "                    ),\n",
    "                    duration=otio.opentime.RationalTime(\n",
    "                        v_gap_timerange.duration.value,\n",
    "                        v_gap_timerange.duration.rate\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # put the clip into the track\n",
    "            vtrack.append(vgap)\n",
    "\n",
    "\n",
    "\n",
    "        #=======================================================\n",
    "        # adding Video clips \n",
    "        #convert the tuple ranges from audio rate to video rate\n",
    "        #audio rate=500\n",
    "\n",
    "                        #add clip to track                \n",
    "\n",
    "            vcl = otio.schema.Clip(\n",
    "                        name=\"vClip{}\".format(i2 + 1),\n",
    "                        media_reference=vref,\n",
    "\n",
    "                        # available_range_from_list is the \n",
    "                        source_range=otio.opentime.TimeRange(\n",
    "                            start_time=otio.opentime.RationalTime(\n",
    "                                v_clip_source_range.start_time.value,\n",
    "                                v_clip_source_range.start_time.rate\n",
    "                            ),\n",
    "                            duration=otio.opentime.RationalTime(\n",
    "                                v_clip_source_range.duration.value,\n",
    "                                v_clip_source_range.duration.rate\n",
    "                            ),\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "            vtrack.append(vcl)\n",
    "\n",
    "            vprevious_end_timecode=tuples[1]/arate*vrate\n",
    "            #apreviousduration=\n",
    "        \n",
    "\n",
    "\n",
    "            i2=i2+1\n",
    "\n",
    "            \n",
    "    i=i+1\n",
    "    #if i == 2:\n",
    "        #break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a401af",
   "metadata": {},
   "source": [
    "# Main speaker audio method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c89026bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# i is to keep track which audio file we are currently on\\ni=-1\\n\\n# i2 is to keep track of how many clips there are\\ni2=0\\n\\nfor lists_of_tuples in list_of_idxmax_mic_data:\\n    #connect the list of tuples to the audio file\\n    #ignore 0 for now. We will come back to this later, i will still be -1 but we will add a default clip instead\\n    \\n    if i==-1:\\n    #add the entire default cam clip in the lowest priority\\n        #vclip\\n        #aclip\\n        pass\\n    \\n    else: \\n        print(AUDIO_VIDEO_TUPLE_LIST[i],VIDEO_FILEPATH_LIST[AUDIO_VIDEO_TUPLE_LIST[i][1]])\\n    \\n        # Connect the audio and video tracks \\n        atrack=atr_list[i]\\n        afname=AUDIO_VIDEO_TUPLE_LIST[i][0]\\n        \\n        # AUDIO_VIDEO_TUPLE_LIST[i][1] references the VIDEO_FILEPATH_LIST to determine which video file to use\\n        vtrack=vtr_list[i]\\n        vfname=VIDEO_FILEPATH_LIST[AUDIO_VIDEO_TUPLE_LIST[i][1]]\\n        \\n        \\n        \\n        #will remember the previous end of clip\\'s timecode\\n        #will reset to 0 when a video-audio track pair is done\\n        vprevious_end_timecode=0\\n        aprevious_end_timecode=0\\n        \\n    #=========================================================================\\n           \\n        for tuples in lists_of_tuples:\\n            \\n        #=====================================================\\n          #adding variables for time and duration calculation\\n            #Video clips \\n            a_clip_starttime=tuples[0]/arate*arate_actual\\n            a_clip_duration=tuples[1]/arate*arate_actual-a_clip_starttime\\n\\n            \\n        #Specifying the start time and end time of the video file where clips come from\\n            a_clip_available_range=otio.opentime.TimeRange(\\n            start_time=otio.opentime.RationalTime(0, arate_actual),\\n            duration=otio.opentime.RationalTime(alength*arate_actual, arate_actual))\\n            \\n            aref = otio.schema.ExternalReference(target_url=afname,\\n            available_range=a_clip_available_range)\\n            \\n            \\n        #specifying where the start timecode and end timecode of the clip is\\n            a_clip_source_range=otio.opentime.TimeRange(\\n                start_time=otio.opentime.RationalTime(a_clip_starttime, arate_actual),\\n                duration=otio.opentime.RationalTime(a_clip_duration, arate_actual))\\n\\n\\n\\n        #Video Gaps\\n            #the gap length is equal to (timecode of next clip time - timecode end of previous clip)\\n            a_gap_start_time=0\\n            a_gap_duration=a_clip_starttime-aprevious_end_timecode\\n            \\n            a_gap_timerange=otio.opentime.TimeRange(\\n                start_time=otio.opentime.RationalTime(a_gap_start_time, arate_actual),\\n                duration=otio.opentime.RationalTime(a_gap_duration, arate_actual))\\n            \\n                \\n            \\n            \\n         #=====================================================   \\n            # adding gaps before adding clips\\n            #convert the tuple ranges from audio rate to video rate\\n                #audio rate=500\\n                #video rate=24\\n\\n\\n\\n            # create gap settings\\n            agap = otio.schema.Gap(\\n                name=\"vGap{}\".format(i2 + 1),\\n\\n                # available_range_from_list is the \\n                source_range=otio.opentime.TimeRange(\\n                    start_time=otio.opentime.RationalTime(\\n                        a_gap_timerange.start_time.value,\\n                        a_gap_timerange.start_time.rate\\n                    ),\\n                    duration=otio.opentime.RationalTime(\\n                        a_gap_timerange.duration.value,\\n                        a_gap_timerange.duration.rate\\n                    ),\\n                )\\n            )\\n\\n            # put the clip into the track\\n            atrack.append(agap)\\n\\n\\n\\n        #=======================================================\\n        # adding Video clips \\n        #convert the tuple ranges from audio rate to video rate\\n        #audio rate=500\\n\\n                        #add clip to track                \\n\\n            acl = otio.schema.Clip(\\n                        name=\"aClip{}\".format(i2 + 1),\\n                        media_reference=aref,\\n\\n                        # available_range_from_list is the \\n                        source_range=otio.opentime.TimeRange(\\n                            start_time=otio.opentime.RationalTime(\\n                                a_clip_source_range.start_time.value,\\n                                a_clip_source_range.start_time.rate\\n                            ),\\n                            duration=otio.opentime.RationalTime(\\n                                a_clip_source_range.duration.value,\\n                                a_clip_source_range.duration.rate\\n                            ),\\n                        )\\n                    )\\n\\n            atrack.append(acl)\\n\\n            aprevious_end_timecode=tuples[1]/arate*arate_actual\\n            #apreviousduration=\\n        \\n\\n\\n            i2=i2+1\\n\\n            \\n    i=i+1\\n    #if i == 2:\\n        #break'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# i is to keep track which audio file we are currently on\n",
    "i=-1\n",
    "\n",
    "# i2 is to keep track of how many clips there are\n",
    "i2=0\n",
    "\n",
    "for lists_of_tuples in list_of_idxmax_mic_data:\n",
    "    #connect the list of tuples to the audio file\n",
    "    #ignore 0 for now. We will come back to this later, i will still be -1 but we will add a default clip instead\n",
    "    \n",
    "    if i==-1:\n",
    "    #add the entire default cam clip in the lowest priority\n",
    "        #vclip\n",
    "        #aclip\n",
    "        pass\n",
    "    \n",
    "    else: \n",
    "        print(AUDIO_VIDEO_TUPLE_LIST[i],VIDEO_FILEPATH_LIST[AUDIO_VIDEO_TUPLE_LIST[i][1]])\n",
    "    \n",
    "        # Connect the audio and video tracks \n",
    "        atrack=atr_list[i]\n",
    "        afname=AUDIO_VIDEO_TUPLE_LIST[i][0]\n",
    "        \n",
    "        # AUDIO_VIDEO_TUPLE_LIST[i][1] references the VIDEO_FILEPATH_LIST to determine which video file to use\n",
    "        vtrack=vtr_list[i]\n",
    "        vfname=VIDEO_FILEPATH_LIST[AUDIO_VIDEO_TUPLE_LIST[i][1]]\n",
    "        \n",
    "        \n",
    "        \n",
    "        #will remember the previous end of clip's timecode\n",
    "        #will reset to 0 when a video-audio track pair is done\n",
    "        vprevious_end_timecode=0\n",
    "        aprevious_end_timecode=0\n",
    "        \n",
    "    #=========================================================================\n",
    "           \n",
    "        for tuples in lists_of_tuples:\n",
    "            \n",
    "        #=====================================================\n",
    "          #adding variables for time and duration calculation\n",
    "            #Video clips \n",
    "            a_clip_starttime=tuples[0]/arate*arate_actual\n",
    "            a_clip_duration=tuples[1]/arate*arate_actual-a_clip_starttime\n",
    "\n",
    "            \n",
    "        #Specifying the start time and end time of the video file where clips come from\n",
    "            a_clip_available_range=otio.opentime.TimeRange(\n",
    "            start_time=otio.opentime.RationalTime(0, arate_actual),\n",
    "            duration=otio.opentime.RationalTime(alength*arate_actual, arate_actual))\n",
    "            \n",
    "            aref = otio.schema.ExternalReference(target_url=afname,\n",
    "            available_range=a_clip_available_range)\n",
    "            \n",
    "            \n",
    "        #specifying where the start timecode and end timecode of the clip is\n",
    "            a_clip_source_range=otio.opentime.TimeRange(\n",
    "                start_time=otio.opentime.RationalTime(a_clip_starttime, arate_actual),\n",
    "                duration=otio.opentime.RationalTime(a_clip_duration, arate_actual))\n",
    "\n",
    "\n",
    "\n",
    "        #Video Gaps\n",
    "            #the gap length is equal to (timecode of next clip time - timecode end of previous clip)\n",
    "            a_gap_start_time=0\n",
    "            a_gap_duration=a_clip_starttime-aprevious_end_timecode\n",
    "            \n",
    "            a_gap_timerange=otio.opentime.TimeRange(\n",
    "                start_time=otio.opentime.RationalTime(a_gap_start_time, arate_actual),\n",
    "                duration=otio.opentime.RationalTime(a_gap_duration, arate_actual))\n",
    "            \n",
    "                \n",
    "            \n",
    "            \n",
    "         #=====================================================   \n",
    "            # adding gaps before adding clips\n",
    "            #convert the tuple ranges from audio rate to video rate\n",
    "                #audio rate=500\n",
    "                #video rate=24\n",
    "\n",
    "\n",
    "\n",
    "            # create gap settings\n",
    "            agap = otio.schema.Gap(\n",
    "                name=\"vGap{}\".format(i2 + 1),\n",
    "\n",
    "                # available_range_from_list is the \n",
    "                source_range=otio.opentime.TimeRange(\n",
    "                    start_time=otio.opentime.RationalTime(\n",
    "                        a_gap_timerange.start_time.value,\n",
    "                        a_gap_timerange.start_time.rate\n",
    "                    ),\n",
    "                    duration=otio.opentime.RationalTime(\n",
    "                        a_gap_timerange.duration.value,\n",
    "                        a_gap_timerange.duration.rate\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # put the clip into the track\n",
    "            atrack.append(agap)\n",
    "\n",
    "\n",
    "\n",
    "        #=======================================================\n",
    "        # adding Video clips \n",
    "        #convert the tuple ranges from audio rate to video rate\n",
    "        #audio rate=500\n",
    "\n",
    "                        #add clip to track                \n",
    "\n",
    "            acl = otio.schema.Clip(\n",
    "                        name=\"aClip{}\".format(i2 + 1),\n",
    "                        media_reference=aref,\n",
    "\n",
    "                        # available_range_from_list is the \n",
    "                        source_range=otio.opentime.TimeRange(\n",
    "                            start_time=otio.opentime.RationalTime(\n",
    "                                a_clip_source_range.start_time.value,\n",
    "                                a_clip_source_range.start_time.rate\n",
    "                            ),\n",
    "                            duration=otio.opentime.RationalTime(\n",
    "                                a_clip_source_range.duration.value,\n",
    "                                a_clip_source_range.duration.rate\n",
    "                            ),\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "            atrack.append(acl)\n",
    "\n",
    "            aprevious_end_timecode=tuples[1]/arate*arate_actual\n",
    "            #apreviousduration=\n",
    "        \n",
    "\n",
    "\n",
    "            i2=i2+1\n",
    "\n",
    "            \n",
    "    i=i+1\n",
    "    #if i == 2:\n",
    "        #break\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c4bd7b",
   "metadata": {},
   "source": [
    "# Loudness Threshold Audio method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07b893f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('E2 - Chukwu.mp3', 1) Hang out 2 Left.mp4\n",
      "('E2 - Osi.mp3', 1) Hang out 2 Left.mp4\n",
      "('E2 - Crystal.mp3', 2) Hang out 2 Right.mp4\n",
      "('E2 - Scott.mp3', 2) Hang out 2 Right.mp4\n"
     ]
    }
   ],
   "source": [
    "# i is to keep track which audio file we are currently on\n",
    "i=0\n",
    "\n",
    "# i2 is to keep track of how many clips there are\n",
    "i2=0\n",
    "\n",
    "for lists_of_tuples in list_of_tuples_threshold_mic_data:\n",
    "    #connect the list of tuples to the audio file\n",
    "    #ignore 0 for now. We will come back to this later, i will still be -1 but we will add a default clip instead\n",
    "    \n",
    "    if i==-1:\n",
    "    #add the entire default cam clip in the lowest priority\n",
    "        #vclip\n",
    "        #aclip\n",
    "        pass\n",
    "    \n",
    "    else: \n",
    "        print(AUDIO_VIDEO_TUPLE_LIST[i],VIDEO_FILEPATH_LIST[AUDIO_VIDEO_TUPLE_LIST[i][1]])\n",
    "    \n",
    "        # Connect the audio and video tracks \n",
    "        atrack=atr_list[i]\n",
    "        afname=AUDIO_VIDEO_TUPLE_LIST[i][0]\n",
    "        \n",
    "        # AUDIO_VIDEO_TUPLE_LIST[i][1] references the VIDEO_FILEPATH_LIST to determine which video file to use\n",
    "        vtrack=vtr_list[i]\n",
    "        vfname=VIDEO_FILEPATH_LIST[AUDIO_VIDEO_TUPLE_LIST[i][1]]\n",
    "        \n",
    "        \n",
    "        \n",
    "        #will remember the previous end of clip's timecode\n",
    "        #will reset to 0 when a video-audio track pair is done\n",
    "        vprevious_end_timecode=0\n",
    "        aprevious_end_timecode=0\n",
    "        \n",
    "    #=========================================================================\n",
    "           \n",
    "        for tuples in lists_of_tuples:\n",
    "            \n",
    "        #=====================================================\n",
    "          #adding variables for time and duration calculation\n",
    "            #Video clips \n",
    "            a_clip_starttime=tuples[0]/arate*arate_actual\n",
    "            a_clip_duration=tuples[1]/arate*arate_actual-a_clip_starttime\n",
    "\n",
    "            \n",
    "        #Specifying the start time and end time of the video file where clips come from\n",
    "            a_clip_available_range=otio.opentime.TimeRange(\n",
    "            start_time=otio.opentime.RationalTime(0, arate_actual),\n",
    "            duration=otio.opentime.RationalTime(alength*arate_actual, arate_actual))\n",
    "            \n",
    "            aref = otio.schema.ExternalReference(target_url=afname,\n",
    "            available_range=a_clip_available_range)\n",
    "            \n",
    "            \n",
    "        #specifying where the start timecode and end timecode of the clip is\n",
    "            a_clip_source_range=otio.opentime.TimeRange(\n",
    "                start_time=otio.opentime.RationalTime(a_clip_starttime, arate_actual),\n",
    "                duration=otio.opentime.RationalTime(a_clip_duration, arate_actual))\n",
    "\n",
    "\n",
    "\n",
    "        #Video Gaps\n",
    "            #the gap length is equal to (timecode of next clip time - timecode end of previous clip)\n",
    "            a_gap_start_time=0\n",
    "            a_gap_duration=a_clip_starttime-aprevious_end_timecode\n",
    "            \n",
    "            a_gap_timerange=otio.opentime.TimeRange(\n",
    "                start_time=otio.opentime.RationalTime(a_gap_start_time, arate_actual),\n",
    "                duration=otio.opentime.RationalTime(a_gap_duration, arate_actual))\n",
    "            \n",
    "                \n",
    "            \n",
    "            \n",
    "         #=====================================================   \n",
    "            # adding gaps before adding clips\n",
    "            #convert the tuple ranges from audio rate to video rate\n",
    "                #audio rate=500\n",
    "                #video rate=24\n",
    "\n",
    "\n",
    "\n",
    "            # create gap settings\n",
    "            agap = otio.schema.Gap(\n",
    "                name=\"vGap{}\".format(i2 + 1),\n",
    "\n",
    "                # available_range_from_list is the \n",
    "                source_range=otio.opentime.TimeRange(\n",
    "                    start_time=otio.opentime.RationalTime(\n",
    "                        a_gap_timerange.start_time.value,\n",
    "                        a_gap_timerange.start_time.rate\n",
    "                    ),\n",
    "                    duration=otio.opentime.RationalTime(\n",
    "                        a_gap_timerange.duration.value,\n",
    "                        a_gap_timerange.duration.rate\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # put the clip into the track\n",
    "            atrack.append(agap)\n",
    "\n",
    "\n",
    "\n",
    "        #=======================================================\n",
    "        # adding Video clips \n",
    "        #convert the tuple ranges from audio rate to video rate\n",
    "        #audio rate=500\n",
    "\n",
    "                        #add clip to track                \n",
    "\n",
    "            acl = otio.schema.Clip(\n",
    "                        name=\"aClip{}\".format(i2 + 1),\n",
    "                        media_reference=aref,\n",
    "\n",
    "                        # available_range_from_list is the \n",
    "                        source_range=otio.opentime.TimeRange(\n",
    "                            start_time=otio.opentime.RationalTime(\n",
    "                                a_clip_source_range.start_time.value,\n",
    "                                a_clip_source_range.start_time.rate\n",
    "                            ),\n",
    "                            duration=otio.opentime.RationalTime(\n",
    "                                a_clip_source_range.duration.value,\n",
    "                                a_clip_source_range.duration.rate\n",
    "                            ),\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "            atrack.append(acl)\n",
    "\n",
    "            aprevious_end_timecode=tuples[1]/arate*arate_actual\n",
    "            #apreviousduration=\n",
    "        \n",
    "\n",
    "\n",
    "            i2=i2+1\n",
    "\n",
    "            \n",
    "    i=i+1\n",
    "    #if i == 2:\n",
    "        #break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd0efb3",
   "metadata": {},
   "source": [
    "# Main cam column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb9f5045",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtrack=main_tr\n",
    "vfname=VIDEO_FILEPATH_LIST[0]\n",
    "\n",
    "#will remember the previous end of clip's timecode\n",
    "#will reset to 0 when a video-audio track pair is done\n",
    "vprevious_end_timecode=0\n",
    "aprevious_end_timecode=0\n",
    "\n",
    "#=========================================================================\n",
    "i=0\n",
    "i2=0\n",
    "for tuples in main_cam_tuple_list_corrected:\n",
    "\n",
    "#=====================================================\n",
    "  #adding variables for time and duration calculation\n",
    "    #Video clips \n",
    "    v_clip_starttime=tuples[0]/arate*vrate\n",
    "    v_clip_duration=tuples[1]/arate*vrate-v_clip_starttime\n",
    "\n",
    "\n",
    "#Specifying the start time and end time of the video file where clips come from\n",
    "    v_clip_available_range=otio.opentime.TimeRange(\n",
    "    start_time=otio.opentime.RationalTime(0, vrate),\n",
    "    duration=otio.opentime.RationalTime(vlength, vrate))\n",
    "\n",
    "    vref = otio.schema.ExternalReference(target_url=vfname,\n",
    "    available_range=v_clip_available_range)\n",
    "\n",
    "\n",
    "#specifying where the start timecode and end timecode of the clip is\n",
    "    v_clip_source_range=otio.opentime.TimeRange(\n",
    "        start_time=otio.opentime.RationalTime(v_clip_starttime, vrate),\n",
    "        duration=otio.opentime.RationalTime(v_clip_duration, vrate))\n",
    "\n",
    "\n",
    "\n",
    "#Video Gaps\n",
    "    #the gap length is equal to (timecode of next clip time - timecode end of previous clip)\n",
    "    v_gap_start_time=0\n",
    "    v_gap_duration=v_clip_starttime-vprevious_end_timecode\n",
    "\n",
    "    v_gap_timerange=otio.opentime.TimeRange(\n",
    "        start_time=otio.opentime.RationalTime(v_gap_start_time, vrate),\n",
    "        duration=otio.opentime.RationalTime(v_gap_duration, vrate))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " #=====================================================   \n",
    "    # adding gaps before adding clips\n",
    "    #convert the tuple ranges from audio rate to video rate\n",
    "        #audio rate=500\n",
    "        #video rate=24\n",
    "\n",
    "\n",
    "\n",
    "    # create gap settings\n",
    "    vgap = otio.schema.Gap(\n",
    "        name=\"vGap{}\".format(i2 + 1),\n",
    "\n",
    "        # available_range_from_list is the \n",
    "        source_range=otio.opentime.TimeRange(\n",
    "            start_time=otio.opentime.RationalTime(\n",
    "                v_gap_timerange.start_time.value,\n",
    "                v_gap_timerange.start_time.rate\n",
    "            ),\n",
    "            duration=otio.opentime.RationalTime(\n",
    "                v_gap_timerange.duration.value,\n",
    "                v_gap_timerange.duration.rate\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # put the clip into the track\n",
    "    vtrack.append(vgap)\n",
    "\n",
    "\n",
    "\n",
    "#=======================================================\n",
    "# adding Video clips \n",
    "#convert the tuple ranges from audio rate to video rate\n",
    "#audio rate=500\n",
    "\n",
    "                #add clip to track                \n",
    "\n",
    "    vcl = otio.schema.Clip(\n",
    "                name=\"vClip{}\".format(i2 + 1),\n",
    "                media_reference=vref,\n",
    "\n",
    "                # available_range_from_list is the \n",
    "                source_range=otio.opentime.TimeRange(\n",
    "                    start_time=otio.opentime.RationalTime(\n",
    "                        v_clip_source_range.start_time.value,\n",
    "                        v_clip_source_range.start_time.rate\n",
    "                    ),\n",
    "                    duration=otio.opentime.RationalTime(\n",
    "                        v_clip_source_range.duration.value,\n",
    "                        v_clip_source_range.duration.rate\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "\n",
    "    vtrack.append(vcl)\n",
    "\n",
    "    vprevious_end_timecode=tuples[1]/arate*vrate\n",
    "    #apreviousduration=\n",
    "\n",
    "\n",
    "\n",
    "    i2=i2+1\n",
    "\n",
    "\n",
    "i=i+1\n",
    "#if i == 2:\n",
    "#break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42f30bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hangout2_threshold.xml'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otio.adapters.write_to_file(tl, 'hangout2_threshold.kdenlive')\n",
    "otio.adapters.write_to_file(tl, 'hangout2_threshold.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "491eb60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#otio.adapters.write_to_file(tl, 'videoaudio_beta2_main.kdenlive')\n",
    "#otio.adapters.write_to_file(tl, 'videoaudio_beta2_main.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3aed1c",
   "metadata": {},
   "source": [
    "# The clip adding via tuple looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b4cdd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
