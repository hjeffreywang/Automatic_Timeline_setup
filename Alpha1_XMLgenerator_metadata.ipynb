{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "419a0c98",
   "metadata": {},
   "source": [
    "# Part 4: XML creation\n",
    "## Dependencies: OTIO and pandas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a85b95ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68910a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pyloudnorm as pyln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ecbceef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: CPU random generator seem to be failing, disabling hardware random number generation\n",
      "WARNING: RDRND generated: 0xffffffff 0xffffffff 0xffffffff 0xffffffff\n"
     ]
    }
   ],
   "source": [
    "#video\n",
    "import moviepy\n",
    "from moviepy.editor import *\n",
    "import opentimelineio as otio\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3a7e8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f9bf31",
   "metadata": {},
   "source": [
    "### Quick summary, OTIO can output XML that CAN be used to import timelines. We just need to learn the behavior and then create a loop to automate clipping, using a imported dataframe as a outline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bb2dd9",
   "metadata": {},
   "source": [
    "# Timeline Outline behavior testing\n",
    "- First create a list of videos\n",
    "    - sfs\n",
    "- Sec create list of audio\n",
    "\n",
    "- Link audio to video, IE if mic1 use center camera\n",
    "\n",
    "## Use the lists of camera and audio to createa loops creating timeranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea588d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_VIDEO_TUPLE_LIST=[(\"Ep 3 - Crystal Audio Extracted.mp3\", 1), (\"Ep 3 - Osi Audio Extracted.mp3\", 1),(\"Ep 3 - Chukwu Audio Extracted.mp3\",2),(\"Ep 3 - Scott Audio Extracted.mp3\",2)]\n",
    "VIDEO_FILEPATH_LIST= [\"E3 Middle.mp4\",\"E3 Osi.mp4\",\"E3 Right.mp4\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b16ac29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_metadata={'fcp_xml': {'@AM.TrackScrollPosition': '0', '@AM.TrackVScrollPosition': '75', '@MZ.EditLine': '6600425832000', '@MZ.Sequence.AudioTimeDisplayFormat': '200', '@MZ.Sequence.EditingModeGUID': '795454d9-d3c2-429d-9474-923ab13b7018', '@MZ.Sequence.PreviewFrameSizeHeight': '1080', '@MZ.Sequence.PreviewFrameSizeWidth': '1920', '@MZ.Sequence.PreviewRenderingClassID': '1061109567', '@MZ.Sequence.PreviewRenderingPresetCodec': '1297107278', '@MZ.Sequence.PreviewRenderingPresetPath': 'EncoderPresets/SequencePreview/795454d9-d3c2-429d-9474-923ab13b7018/I-Frame Only MPEG.epr', '@MZ.Sequence.PreviewUseMaxBitDepth': 'false', '@MZ.Sequence.PreviewUseMaxRenderQuality': 'false', '@MZ.Sequence.VideoTimeDisplayFormat': '110', '@Monitor.ProgramZoomIn': '0', '@Monitor.ProgramZoomOut': '279167288400000', '@TL.SQAVDividerPosition': '0.5', '@TL.SQAudioVisibleBase': '0', '@TL.SQHeaderWidth': '236', '@TL.SQHideShyTracks': '0', '@TL.SQTimePerPixel': '0.19999999999999998', '@TL.SQVideoVisibleBase': '0', '@TL.SQVisibleBaseTime': '0', '@explodedTracks': 'true', '@id': 'sequence-2', 'labels': {'label2': 'Forest'}, 'logginginfo': {'description': None, 'good': None, 'lognote': None, 'originalaudiofilename': None, 'originalvideofilename': None, 'scene': None, 'shottake': None}, 'media': {'audio': {'format': {'samplecharacteristics': {'depth': '16', 'samplerate': '48000'}}, 'numOutputChannels': '2', 'outputs': {'group': [{'channel': {'index': '1'}, 'downmix': '0', 'index': '1', 'numchannels': '1'}, {'channel': {'index': '2'}, 'downmix': '0', 'index': '2', 'numchannels': '1'}]}}, 'video': {'format': {'samplecharacteristics': {'anamorphic': 'FALSE', 'codec': {'appspecificdata': {'appmanufacturer': 'Apple Inc.', 'appname': 'Final Cut Pro', 'appversion': '7.0', 'data': {'qtcodec': {'codecname': 'Apple ProRes 422', 'codectypecode': 'apcn', 'codectypename': 'Apple ProRes 422', 'codecvendorcode': 'appl', 'datarate': '0', 'keyframerate': '0', 'spatialquality': '1024', 'temporalquality': '0'}}}, 'name': 'Apple ProRes 422'}, 'colordepth': '24', 'fielddominance': 'none', 'height': '2160', 'pixelaspectratio': 'square', 'rate': {'ntsc': 'TRUE', 'timebase': '24'}, 'width': '3840'}}}}, 'rate': {'ntsc': 'TRUE', 'timebase': '24'}, 'timecode': {'displayformat': 'NDF', 'rate': {'ntsc': 'TRUE', 'timebase': '24'}}, 'uuid': '377abc11-205d-498b-b058-6e73c151d97f'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03efb571",
   "metadata": {},
   "source": [
    "# Further data editing \n",
    "\n",
    "## Create a camera view column that matches the audio_video_tuple to  idxmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f07ad689",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df=pd.read_pickle('idxmax.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76ba6d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use indexes of when crossover is 1 to change cam_view to 0 for three seconds after crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62f6cb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap = cv2. VideoCapture(VIDEO_FILEPATH_LIST[0])\n",
    "vlength = int(cap. get(cv2. CAP_PROP_FRAME_COUNT))\n",
    "alength=len(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bc36f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79779"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alength\n",
    "vlength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "788196d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vrate=24\n",
    "arate=500\n",
    "arate_actual=24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df113f99",
   "metadata": {},
   "source": [
    "## Create intervals of data in tuple form. \n",
    "\n",
    "## idxmax_mic_data are Video Tuples which  represent the start and end frame of main speaker. Can be used for audio data as well when there is sufficient mic bleed.\n",
    "\n",
    "## threshold_mic_data are Audio Tuples represent the start and end frame of when mic is being used.\n",
    "\n",
    "\n",
    "## Main cam tuples use the main cam column in the dataframe to change to center cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbf64797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_getintervals(series,desiredvalue):\n",
    "    #make sure series is the df['column']\n",
    "    t=series.index[series==desiredvalue].to_series()\n",
    "    interval_list=t.groupby(t.diff().ne(1).cumsum()).agg(['first','last']).apply(tuple,1).tolist()\n",
    "    \n",
    "    return interval_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcb2df49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create lists of tuples for each camera based on the audio\n",
    "\n",
    "list_of_idxmax_mic_data=[]\n",
    "for i in range(len(AUDIO_VIDEO_TUPLE_LIST)+1):\n",
    "    tuple_list=dataframe_getintervals(data_df['idxmax'],i)\n",
    "    list_of_idxmax_mic_data.append(tuple_list)\n",
    "\n",
    "    \n",
    "##create lists of tuples for each Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d80e0dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Audio Tuples\n",
    "#creating a list to referencing the column names of df \n",
    "list_str_audio_thresholds=[]\n",
    "for irow in range(len(AUDIO_VIDEO_TUPLE_LIST)):\n",
    "    varname=\"A\"\n",
    "    list_str_audio_thresholds.append(varname+str(irow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49637034",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create lists of tuples for each audio based the threshold region\n",
    "list_of_tuples_threshold_mic_data=[]\n",
    "for i in range(len(AUDIO_VIDEO_TUPLE_LIST)):\n",
    "    tuple_list=dataframe_getintervals(data_df[list_str_audio_thresholds[i]],1)\n",
    "    list_of_tuples_threshold_mic_data.append(tuple_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52b0fdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main cam tuple list\n",
    "main_cam_tuple_list=dataframe_getintervals(data_df['Main_cam'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7ec7cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_cam_tuple_list_corrected=[]\n",
    "guard=0\n",
    "count=0\n",
    "#add 3 seconds to the end of every transition\n",
    "for i in range(len(main_cam_tuple_list)):\n",
    "    \n",
    "    if guard==0:\n",
    "        \n",
    "        if i+1==len(main_cam_tuple_list):\n",
    "            pass\n",
    "        else:\n",
    "            if main_cam_tuple_list[i+1][0]-main_cam_tuple_list[i][1]<arate*3:\n",
    "                #create tuple\n",
    "                new_tuple=(main_cam_tuple_list[i][0],main_cam_tuple_list[i+1][1])\n",
    "                #add tuple to list\n",
    "                main_cam_tuple_list_corrected.append(new_tuple)\n",
    "                guard=1\n",
    "\n",
    "            else:\n",
    "                main_cam_tuple_list_corrected.append(main_cam_tuple_list[i])\n",
    "    \n",
    "    else:\n",
    "        guard=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af7b89ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_audio_idxmax_mic_data=[]\n",
    "\n",
    "for i in range(len(list_of_idxmax_mic_data)):\n",
    "#for each list of tuple in the list\n",
    "    new_tuple_list=[]\n",
    "    \n",
    "    for i2 in range(len(list_of_idxmax_mic_data[i])):\n",
    "    #for each element in tuple, add 1.5 seconds to the clip\n",
    "        \n",
    "        extended_tuple=(list_of_idxmax_mic_data[i][i2][0]+arate*1.5,list_of_idxmax_mic_data[i][i2][1]+arate*1.5)\n",
    "        \n",
    "        \n",
    "        \n",
    "        new_tuple_list.append(extended_tuple)\n",
    "        \n",
    " \n",
    "    \n",
    "    extended_audio_idxmax_mic_data.append(new_tuple_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f753b42a",
   "metadata": {},
   "source": [
    "## Create extra center cam intervals for long unchanged camera focus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4b713c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "(222704, 226704) (215204, 232849) 35.29\n",
      "True\n",
      "(446062, 450062) (438562, 455763) 34.402\n",
      "True\n",
      "(782894, 786894) (775394, 792034) 33.28\n",
      "True\n",
      "(805655, 809655) (798155, 830612) 64.914\n",
      "(813155, 817155) (798155, 830612) 64.914\n",
      "(820655, 824655) (798155, 830612) 64.914\n",
      "True\n",
      "(937412, 941412) (929912, 947879) 35.934\n",
      "True\n",
      "(1293126, 1297126) (1285626, 1310587) 49.922\n",
      "(1300626, 1304626) (1285626, 1310587) 49.922\n",
      "True\n",
      "(300943, 304943) (293443, 331962) 77.038\n",
      "(308443, 312443) (293443, 331962) 77.038\n",
      "(315943, 319943) (293443, 331962) 77.038\n",
      "(323443, 327443) (293443, 331962) 77.038\n",
      "True\n",
      "(838113, 842113) (830613, 854246) 47.266\n",
      "(845613, 849613) (830613, 854246) 47.266\n",
      "True\n",
      "(101372, 105372) (93872, 111699) 35.654\n",
      "True\n",
      "(159617, 163617) (152117, 175822) 47.41\n",
      "(167117, 171117) (152117, 175822) 47.41\n",
      "True\n",
      "(189889, 193889) (182389, 199539) 34.3\n",
      "True\n",
      "(496441, 500441) (488941, 508067) 38.252\n",
      "True\n",
      "(914655, 918655) (907155, 925815) 37.32\n",
      "True\n",
      "(955380, 959380) (947880, 966383) 37.006\n",
      "True\n",
      "(27142, 31142) (19642, 50451) 61.618\n",
      "(34642, 38642) (19642, 50451) 61.618\n",
      "(42142, 46142) (19642, 50451) 61.618\n",
      "True\n",
      "(339463, 343463) (331963, 363095) 62.264\n",
      "(346963, 350963) (331963, 363095) 62.264\n",
      "(354463, 358463) (331963, 363095) 62.264\n",
      "True\n",
      "(463264, 467264) (455764, 473787) 36.046\n"
     ]
    }
   ],
   "source": [
    "#append bits of center cam to diversify long lengths of non-center cam\n",
    "for lists_of_tuples in list_of_idxmax_mic_data:\n",
    "    for tuples in lists_of_tuples:\n",
    "        length=tuples[1]-tuples[0]\n",
    "        if tuples[1]-tuples[0]>30*arate:\n",
    "            interval_num=math.floor(length/(15*arate))\n",
    "            if tuples[1]<tuples[0]+interval_num*15*arate+10*arate:\n",
    "                interval_num=interval_num-1\n",
    "                print(True)\n",
    "                \n",
    "                \n",
    "                for i in range(interval_num):\n",
    "\n",
    "                    tup_start=tuples[0]+(i+1)*15*arate\n",
    "                    tup_end=tup_start+8*arate\n",
    "                    new_tuple=(tup_start,tup_end)\n",
    "                    print(new_tuple , tuples ,length/arate)\n",
    "                    main_cam_tuple_list_corrected.append(new_tuple)\n",
    "            \n",
    "            #interval=tuple()\n",
    "        #main_cam_tuple_list.append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f395576",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_cam_tuple_list_corrected.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55566332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#skeletal outline of otio\n",
    "\n",
    "\n",
    "# build the structure\n",
    "tl = otio.schema.Timeline(name=\"Example timeline\", metadata=example_metadata)\n",
    "\n",
    "# add track for each video file and each audio file\n",
    "#for each file add a track\n",
    "\n",
    "#create lists for each track to reference back to later\n",
    "#vtr is video track, etc.\n",
    "vtr_list=[]\n",
    "atr_list=[]\n",
    "\n",
    "\n",
    "#add a audio AND video track for each video track\n",
    "    #default cam first because it is lowest priority\n",
    "vtr_default = otio.schema.Track(name=\"Default_camera\", kind=\"Video\")\n",
    "tl.tracks.append(vtr_default)\n",
    "\n",
    "for i in AUDIO_VIDEO_TUPLE_LIST:\n",
    "    atr = otio.schema.Track(name=i[0], kind=\"Audio\")\n",
    "    tl.tracks.append(atr)\n",
    "    atr_list.append(atr)\n",
    "    \n",
    "    #video\n",
    "    vtr = otio.schema.Track(name=i[0]+\"_video\", kind=\"Video\")\n",
    "    tl.tracks.append(vtr)\n",
    "    vtr_list.append(vtr)\n",
    "\n",
    "# add main cam\n",
    "main_tr = otio.schema.Track(name='Main_Cam')\n",
    "tl.tracks.append(main_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c171267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vrate=24\n",
    "arate=500\n",
    "arate_actual=24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2ec573",
   "metadata": {},
   "source": [
    "# Two different loops, One for Video, another for audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1e12861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#video clips\n",
    "# i is to keep track which audio file we are currently on\n",
    "i=-1\n",
    "\n",
    "# i2 is to keep track of how many clips there are\n",
    "i2=0\n",
    "\n",
    "for lists_of_tuples in list_of_idxmax_mic_data:\n",
    "    #connect the list of tuples to the audio file\n",
    "    #ignore 0 for now. We will come back to this later, i will still be -1 but we will add a default clip instead\n",
    "    \n",
    "    if i==-1:\n",
    "    #add the entire default cam clip in the lowest priority\n",
    "        #vclip\n",
    "        #aclip\n",
    "        pass\n",
    "    \n",
    "    else: \n",
    "        #print(AUDIO_VIDEO_TUPLE_LIST[i],VIDEO_FILEPATH_LIST[AUDIO_VIDEO_TUPLE_LIST[i][1]])\n",
    "    \n",
    "        # Connect the audio and video tracks \n",
    "        atrack=atr_list[i]\n",
    "        afname=AUDIO_VIDEO_TUPLE_LIST[i][0]\n",
    "        \n",
    "        # AUDIO_VIDEO_TUPLE_LIST[i][1] references the VIDEO_FILEPATH_LIST to determine which video file to use\n",
    "        vtrack=vtr_list[i]\n",
    "        vfname=VIDEO_FILEPATH_LIST[AUDIO_VIDEO_TUPLE_LIST[i][1]]\n",
    "        \n",
    "        \n",
    "        \n",
    "        #will remember the previous end of clip's timecode\n",
    "        #will reset to 0 when a video-audio track pair is done\n",
    "        vprevious_end_timecode=0\n",
    "        aprevious_end_timecode=0\n",
    "        \n",
    "    #=========================================================================\n",
    "           \n",
    "        for tuples in lists_of_tuples:\n",
    "            \n",
    "        #=====================================================\n",
    "          #adding variables for time and duration calculation\n",
    "            #Video clips \n",
    "            v_clip_starttime=tuples[0]/arate*vrate\n",
    "            v_clip_duration=tuples[1]/arate*vrate-v_clip_starttime\n",
    "\n",
    "            \n",
    "        #Specifying the start time and end time of the video file where clips come from\n",
    "            v_clip_available_range=otio.opentime.TimeRange(\n",
    "            start_time=otio.opentime.RationalTime(0, vrate),\n",
    "            duration=otio.opentime.RationalTime(vlength, vrate))\n",
    "            \n",
    "            vref = otio.schema.ExternalReference(target_url=vfname,\n",
    "            available_range=v_clip_available_range)\n",
    "            \n",
    "            \n",
    "        #specifying where the start timecode and end timecode of the clip is\n",
    "            v_clip_source_range=otio.opentime.TimeRange(\n",
    "                start_time=otio.opentime.RationalTime(v_clip_starttime, vrate),\n",
    "                duration=otio.opentime.RationalTime(v_clip_duration, vrate))\n",
    "\n",
    "\n",
    "\n",
    "        #Video Gaps\n",
    "            #the gap length is equal to (timecode of next clip time - timecode end of previous clip)\n",
    "            v_gap_start_time=0\n",
    "            v_gap_duration=v_clip_starttime-vprevious_end_timecode\n",
    "            \n",
    "            v_gap_timerange=otio.opentime.TimeRange(\n",
    "                start_time=otio.opentime.RationalTime(v_gap_start_time, vrate),\n",
    "                duration=otio.opentime.RationalTime(v_gap_duration, vrate))\n",
    "            \n",
    "                \n",
    "            \n",
    "            \n",
    "         #=====================================================   \n",
    "            # adding gaps before adding clips\n",
    "            #convert the tuple ranges from audio rate to video rate\n",
    "                #audio rate=500\n",
    "                #video rate=24\n",
    "\n",
    "\n",
    "\n",
    "            # create gap settings\n",
    "            vgap = otio.schema.Gap(\n",
    "                name=\"vGap{}\".format(i2 + 1),\n",
    "\n",
    "                # available_range_from_list is the \n",
    "                source_range=otio.opentime.TimeRange(\n",
    "                    start_time=otio.opentime.RationalTime(\n",
    "                        v_gap_timerange.start_time.value,\n",
    "                        v_gap_timerange.start_time.rate\n",
    "                    ),\n",
    "                    duration=otio.opentime.RationalTime(\n",
    "                        v_gap_timerange.duration.value,\n",
    "                        v_gap_timerange.duration.rate\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # put the clip into the track\n",
    "            vtrack.append(vgap)\n",
    "\n",
    "\n",
    "\n",
    "        #=======================================================\n",
    "        # adding Video clips \n",
    "        #convert the tuple ranges from audio rate to video rate\n",
    "        #audio rate=500\n",
    "\n",
    "                        #add clip to track                \n",
    "\n",
    "            vcl = otio.schema.Clip(\n",
    "                        name=\"vClip{}\".format(i2 + 1),\n",
    "                        media_reference=vref,\n",
    "\n",
    "                        # available_range_from_list is the \n",
    "                        source_range=otio.opentime.TimeRange(\n",
    "                            start_time=otio.opentime.RationalTime(\n",
    "                                v_clip_source_range.start_time.value,\n",
    "                                v_clip_source_range.start_time.rate\n",
    "                            ),\n",
    "                            duration=otio.opentime.RationalTime(\n",
    "                                v_clip_source_range.duration.value,\n",
    "                                v_clip_source_range.duration.rate\n",
    "                            ),\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "            vtrack.append(vcl)\n",
    "\n",
    "            vprevious_end_timecode=tuples[1]/arate*vrate\n",
    "            #apreviousduration=\n",
    "        \n",
    "\n",
    "\n",
    "            i2=i2+1\n",
    "\n",
    "            \n",
    "    i=i+1\n",
    "    #if i == 2:\n",
    "        #break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a401af",
   "metadata": {},
   "source": [
    "# Main speaker audio method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c89026bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# i is to keep track which audio file we are currently on\\ni=-1\\n\\n# i2 is to keep track of how many clips there are\\ni2=0\\n\\nfor lists_of_tuples in list_of_idxmax_mic_data:\\n    #connect the list of tuples to the audio file\\n    #ignore 0 for now. We will come back to this later, i will still be -1 but we will add a default clip instead\\n    \\n    if i==-1:\\n    #add the entire default cam clip in the lowest priority\\n        #vclip\\n        #aclip\\n        pass\\n    \\n    else: \\n        print(AUDIO_VIDEO_TUPLE_LIST[i],VIDEO_FILEPATH_LIST[AUDIO_VIDEO_TUPLE_LIST[i][1]])\\n    \\n        # Connect the audio and video tracks \\n        atrack=atr_list[i]\\n        afname=AUDIO_VIDEO_TUPLE_LIST[i][0]\\n        \\n        # AUDIO_VIDEO_TUPLE_LIST[i][1] references the VIDEO_FILEPATH_LIST to determine which video file to use\\n        vtrack=vtr_list[i]\\n        vfname=VIDEO_FILEPATH_LIST[AUDIO_VIDEO_TUPLE_LIST[i][1]]\\n        \\n        \\n        \\n        #will remember the previous end of clip\\'s timecode\\n        #will reset to 0 when a video-audio track pair is done\\n        vprevious_end_timecode=0\\n        aprevious_end_timecode=0\\n        \\n    #=========================================================================\\n           \\n        for tuples in lists_of_tuples:\\n            \\n        #=====================================================\\n          #adding variables for time and duration calculation\\n            #Video clips \\n            a_clip_starttime=tuples[0]/arate*arate_actual\\n            a_clip_duration=tuples[1]/arate*arate_actual-a_clip_starttime\\n\\n            \\n        #Specifying the start time and end time of the video file where clips come from\\n            a_clip_available_range=otio.opentime.TimeRange(\\n            start_time=otio.opentime.RationalTime(0, arate_actual),\\n            duration=otio.opentime.RationalTime(alength*arate_actual, arate_actual))\\n            \\n            aref = otio.schema.ExternalReference(target_url=afname,\\n            available_range=a_clip_available_range)\\n            \\n            \\n        #specifying where the start timecode and end timecode of the clip is\\n            a_clip_source_range=otio.opentime.TimeRange(\\n                start_time=otio.opentime.RationalTime(a_clip_starttime, arate_actual),\\n                duration=otio.opentime.RationalTime(a_clip_duration, arate_actual))\\n\\n\\n\\n        #Video Gaps\\n            #the gap length is equal to (timecode of next clip time - timecode end of previous clip)\\n            a_gap_start_time=0\\n            a_gap_duration=a_clip_starttime-aprevious_end_timecode\\n            \\n            a_gap_timerange=otio.opentime.TimeRange(\\n                start_time=otio.opentime.RationalTime(a_gap_start_time, arate_actual),\\n                duration=otio.opentime.RationalTime(a_gap_duration, arate_actual))\\n            \\n                \\n            \\n            \\n         #=====================================================   \\n            # adding gaps before adding clips\\n            #convert the tuple ranges from audio rate to video rate\\n                #audio rate=500\\n                #video rate=24\\n\\n\\n\\n            # create gap settings\\n            agap = otio.schema.Gap(\\n                name=\"vGap{}\".format(i2 + 1),\\n\\n                # available_range_from_list is the \\n                source_range=otio.opentime.TimeRange(\\n                    start_time=otio.opentime.RationalTime(\\n                        a_gap_timerange.start_time.value,\\n                        a_gap_timerange.start_time.rate\\n                    ),\\n                    duration=otio.opentime.RationalTime(\\n                        a_gap_timerange.duration.value,\\n                        a_gap_timerange.duration.rate\\n                    ),\\n                )\\n            )\\n\\n            # put the clip into the track\\n            atrack.append(agap)\\n\\n\\n\\n        #=======================================================\\n        # adding Video clips \\n        #convert the tuple ranges from audio rate to video rate\\n        #audio rate=500\\n\\n                        #add clip to track                \\n\\n            acl = otio.schema.Clip(\\n                        name=\"aClip{}\".format(i2 + 1),\\n                        media_reference=aref,\\n\\n                        # available_range_from_list is the \\n                        source_range=otio.opentime.TimeRange(\\n                            start_time=otio.opentime.RationalTime(\\n                                a_clip_source_range.start_time.value,\\n                                a_clip_source_range.start_time.rate\\n                            ),\\n                            duration=otio.opentime.RationalTime(\\n                                a_clip_source_range.duration.value,\\n                                a_clip_source_range.duration.rate\\n                            ),\\n                        )\\n                    )\\n\\n            atrack.append(acl)\\n\\n            aprevious_end_timecode=tuples[1]/arate*arate_actual\\n            #apreviousduration=\\n        \\n\\n\\n            i2=i2+1\\n\\n            \\n    i=i+1\\n    #if i == 2:\\n        #break'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# i is to keep track which audio file we are currently on\n",
    "i=-1\n",
    "\n",
    "# i2 is to keep track of how many clips there are\n",
    "i2=0\n",
    "\n",
    "for lists_of_tuples in list_of_idxmax_mic_data:\n",
    "    #connect the list of tuples to the audio file\n",
    "    #ignore 0 for now. We will come back to this later, i will still be -1 but we will add a default clip instead\n",
    "    \n",
    "    if i==-1:\n",
    "    #add the entire default cam clip in the lowest priority\n",
    "        #vclip\n",
    "        #aclip\n",
    "        pass\n",
    "    \n",
    "    else: \n",
    "        print(AUDIO_VIDEO_TUPLE_LIST[i],VIDEO_FILEPATH_LIST[AUDIO_VIDEO_TUPLE_LIST[i][1]])\n",
    "    \n",
    "        # Connect the audio and video tracks \n",
    "        atrack=atr_list[i]\n",
    "        afname=AUDIO_VIDEO_TUPLE_LIST[i][0]\n",
    "        \n",
    "        # AUDIO_VIDEO_TUPLE_LIST[i][1] references the VIDEO_FILEPATH_LIST to determine which video file to use\n",
    "        vtrack=vtr_list[i]\n",
    "        vfname=VIDEO_FILEPATH_LIST[AUDIO_VIDEO_TUPLE_LIST[i][1]]\n",
    "        \n",
    "        \n",
    "        \n",
    "        #will remember the previous end of clip's timecode\n",
    "        #will reset to 0 when a video-audio track pair is done\n",
    "        vprevious_end_timecode=0\n",
    "        aprevious_end_timecode=0\n",
    "        \n",
    "    #=========================================================================\n",
    "           \n",
    "        for tuples in lists_of_tuples:\n",
    "            \n",
    "        #=====================================================\n",
    "          #adding variables for time and duration calculation\n",
    "            #Video clips \n",
    "            a_clip_starttime=tuples[0]/arate*arate_actual\n",
    "            a_clip_duration=tuples[1]/arate*arate_actual-a_clip_starttime\n",
    "\n",
    "            \n",
    "        #Specifying the start time and end time of the video file where clips come from\n",
    "            a_clip_available_range=otio.opentime.TimeRange(\n",
    "            start_time=otio.opentime.RationalTime(0, arate_actual),\n",
    "            duration=otio.opentime.RationalTime(alength*arate_actual, arate_actual))\n",
    "            \n",
    "            aref = otio.schema.ExternalReference(target_url=afname,\n",
    "            available_range=a_clip_available_range)\n",
    "            \n",
    "            \n",
    "        #specifying where the start timecode and end timecode of the clip is\n",
    "            a_clip_source_range=otio.opentime.TimeRange(\n",
    "                start_time=otio.opentime.RationalTime(a_clip_starttime, arate_actual),\n",
    "                duration=otio.opentime.RationalTime(a_clip_duration, arate_actual))\n",
    "\n",
    "\n",
    "\n",
    "        #Video Gaps\n",
    "            #the gap length is equal to (timecode of next clip time - timecode end of previous clip)\n",
    "            a_gap_start_time=0\n",
    "            a_gap_duration=a_clip_starttime-aprevious_end_timecode\n",
    "            \n",
    "            a_gap_timerange=otio.opentime.TimeRange(\n",
    "                start_time=otio.opentime.RationalTime(a_gap_start_time, arate_actual),\n",
    "                duration=otio.opentime.RationalTime(a_gap_duration, arate_actual))\n",
    "            \n",
    "                \n",
    "            \n",
    "            \n",
    "         #=====================================================   \n",
    "            # adding gaps before adding clips\n",
    "            #convert the tuple ranges from audio rate to video rate\n",
    "                #audio rate=500\n",
    "                #video rate=24\n",
    "\n",
    "\n",
    "\n",
    "            # create gap settings\n",
    "            agap = otio.schema.Gap(\n",
    "                name=\"vGap{}\".format(i2 + 1),\n",
    "\n",
    "                # available_range_from_list is the \n",
    "                source_range=otio.opentime.TimeRange(\n",
    "                    start_time=otio.opentime.RationalTime(\n",
    "                        a_gap_timerange.start_time.value,\n",
    "                        a_gap_timerange.start_time.rate\n",
    "                    ),\n",
    "                    duration=otio.opentime.RationalTime(\n",
    "                        a_gap_timerange.duration.value,\n",
    "                        a_gap_timerange.duration.rate\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # put the clip into the track\n",
    "            atrack.append(agap)\n",
    "\n",
    "\n",
    "\n",
    "        #=======================================================\n",
    "        # adding Video clips \n",
    "        #convert the tuple ranges from audio rate to video rate\n",
    "        #audio rate=500\n",
    "\n",
    "                        #add clip to track                \n",
    "\n",
    "            acl = otio.schema.Clip(\n",
    "                        name=\"aClip{}\".format(i2 + 1),\n",
    "                        media_reference=aref,\n",
    "\n",
    "                        # available_range_from_list is the \n",
    "                        source_range=otio.opentime.TimeRange(\n",
    "                            start_time=otio.opentime.RationalTime(\n",
    "                                a_clip_source_range.start_time.value,\n",
    "                                a_clip_source_range.start_time.rate\n",
    "                            ),\n",
    "                            duration=otio.opentime.RationalTime(\n",
    "                                a_clip_source_range.duration.value,\n",
    "                                a_clip_source_range.duration.rate\n",
    "                            ),\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "            atrack.append(acl)\n",
    "\n",
    "            aprevious_end_timecode=tuples[1]/arate*arate_actual\n",
    "            #apreviousduration=\n",
    "        \n",
    "\n",
    "\n",
    "            i2=i2+1\n",
    "\n",
    "            \n",
    "    i=i+1\n",
    "    #if i == 2:\n",
    "        #break\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c4bd7b",
   "metadata": {},
   "source": [
    "# Loudness Threshold Audio method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07b893f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Ep 3 - Crystal Audio Extracted.mp3', 1) E3 Osi.mp4\n",
      "('Ep 3 - Osi Audio Extracted.mp3', 1) E3 Osi.mp4\n",
      "('Ep 3 - Chukwu Audio Extracted.mp3', 2) E3 Right.mp4\n",
      "('Ep 3 - Scott Audio Extracted.mp3', 2) E3 Right.mp4\n"
     ]
    }
   ],
   "source": [
    "# i is to keep track which audio file we are currently on\n",
    "i=0\n",
    "\n",
    "# i2 is to keep track of how many clips there are\n",
    "i2=0\n",
    "\n",
    "for lists_of_tuples in list_of_tuples_threshold_mic_data:\n",
    "    #connect the list of tuples to the audio file\n",
    "    #ignore 0 for now. We will come back to this later, i will still be -1 but we will add a default clip instead\n",
    "    \n",
    "    if i==-1:\n",
    "    #add the entire default cam clip in the lowest priority\n",
    "        #vclip\n",
    "        #aclip\n",
    "        pass\n",
    "    \n",
    "    else: \n",
    "        print(AUDIO_VIDEO_TUPLE_LIST[i],VIDEO_FILEPATH_LIST[AUDIO_VIDEO_TUPLE_LIST[i][1]])\n",
    "    \n",
    "        # Connect the audio and video tracks \n",
    "        atrack=atr_list[i]\n",
    "        afname=AUDIO_VIDEO_TUPLE_LIST[i][0]\n",
    "        \n",
    "        # AUDIO_VIDEO_TUPLE_LIST[i][1] references the VIDEO_FILEPATH_LIST to determine which video file to use\n",
    "        vtrack=vtr_list[i]\n",
    "        vfname=VIDEO_FILEPATH_LIST[AUDIO_VIDEO_TUPLE_LIST[i][1]]\n",
    "        \n",
    "        \n",
    "        \n",
    "        #will remember the previous end of clip's timecode\n",
    "        #will reset to 0 when a video-audio track pair is done\n",
    "        vprevious_end_timecode=0\n",
    "        aprevious_end_timecode=0\n",
    "        \n",
    "    #=========================================================================\n",
    "           \n",
    "        for tuples in lists_of_tuples:\n",
    "            \n",
    "        #=====================================================\n",
    "          #adding variables for time and duration calculation\n",
    "            #Video clips \n",
    "            a_clip_starttime=tuples[0]/arate*arate_actual\n",
    "            a_clip_duration=tuples[1]/arate*arate_actual-a_clip_starttime\n",
    "\n",
    "            \n",
    "        #Specifying the start time and end time of the video file where clips come from\n",
    "            a_clip_available_range=otio.opentime.TimeRange(\n",
    "            start_time=otio.opentime.RationalTime(0, arate_actual),\n",
    "            duration=otio.opentime.RationalTime(alength*arate_actual, arate_actual))\n",
    "            \n",
    "            aref = otio.schema.ExternalReference(target_url=afname,\n",
    "            available_range=a_clip_available_range)\n",
    "            \n",
    "            \n",
    "        #specifying where the start timecode and end timecode of the clip is\n",
    "            a_clip_source_range=otio.opentime.TimeRange(\n",
    "                start_time=otio.opentime.RationalTime(a_clip_starttime, arate_actual),\n",
    "                duration=otio.opentime.RationalTime(a_clip_duration, arate_actual))\n",
    "\n",
    "\n",
    "\n",
    "        #Video Gaps\n",
    "            #the gap length is equal to (timecode of next clip time - timecode end of previous clip)\n",
    "            a_gap_start_time=0\n",
    "            a_gap_duration=a_clip_starttime-aprevious_end_timecode\n",
    "            \n",
    "            a_gap_timerange=otio.opentime.TimeRange(\n",
    "                start_time=otio.opentime.RationalTime(a_gap_start_time, arate_actual),\n",
    "                duration=otio.opentime.RationalTime(a_gap_duration, arate_actual))\n",
    "            \n",
    "                \n",
    "            \n",
    "            \n",
    "         #=====================================================   \n",
    "            # adding gaps before adding clips\n",
    "            #convert the tuple ranges from audio rate to video rate\n",
    "                #audio rate=500\n",
    "                #video rate=24\n",
    "\n",
    "\n",
    "\n",
    "            # create gap settings\n",
    "            agap = otio.schema.Gap(\n",
    "                name=\"vGap{}\".format(i2 + 1),\n",
    "\n",
    "                # available_range_from_list is the \n",
    "                source_range=otio.opentime.TimeRange(\n",
    "                    start_time=otio.opentime.RationalTime(\n",
    "                        a_gap_timerange.start_time.value,\n",
    "                        a_gap_timerange.start_time.rate\n",
    "                    ),\n",
    "                    duration=otio.opentime.RationalTime(\n",
    "                        a_gap_timerange.duration.value,\n",
    "                        a_gap_timerange.duration.rate\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # put the clip into the track\n",
    "            atrack.append(agap)\n",
    "\n",
    "\n",
    "\n",
    "        #=======================================================\n",
    "        # adding Video clips \n",
    "        #convert the tuple ranges from audio rate to video rate\n",
    "        #audio rate=500\n",
    "\n",
    "                        #add clip to track                \n",
    "\n",
    "            acl = otio.schema.Clip(\n",
    "                        name=\"aClip{}\".format(i2 + 1),\n",
    "                        media_reference=aref,\n",
    "\n",
    "                        # available_range_from_list is the \n",
    "                        source_range=otio.opentime.TimeRange(\n",
    "                            start_time=otio.opentime.RationalTime(\n",
    "                                a_clip_source_range.start_time.value,\n",
    "                                a_clip_source_range.start_time.rate\n",
    "                            ),\n",
    "                            duration=otio.opentime.RationalTime(\n",
    "                                a_clip_source_range.duration.value,\n",
    "                                a_clip_source_range.duration.rate\n",
    "                            ),\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "            atrack.append(acl)\n",
    "\n",
    "            aprevious_end_timecode=tuples[1]/arate*arate_actual\n",
    "            #apreviousduration=\n",
    "        \n",
    "\n",
    "\n",
    "            i2=i2+1\n",
    "\n",
    "            \n",
    "    i=i+1\n",
    "    #if i == 2:\n",
    "        #break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd0efb3",
   "metadata": {},
   "source": [
    "# Main cam column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb9f5045",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtrack=main_tr\n",
    "vfname=VIDEO_FILEPATH_LIST[0]\n",
    "\n",
    "#will remember the previous end of clip's timecode\n",
    "#will reset to 0 when a video-audio track pair is done\n",
    "vprevious_end_timecode=0\n",
    "aprevious_end_timecode=0\n",
    "\n",
    "#=========================================================================\n",
    "i=0\n",
    "i2=0\n",
    "for tuples in main_cam_tuple_list_corrected:\n",
    "\n",
    "#=====================================================\n",
    "  #adding variables for time and duration calculation\n",
    "    #Video clips \n",
    "    v_clip_starttime=tuples[0]/arate*vrate\n",
    "    v_clip_duration=tuples[1]/arate*vrate-v_clip_starttime\n",
    "\n",
    "\n",
    "#Specifying the start time and end time of the video file where clips come from\n",
    "    v_clip_available_range=otio.opentime.TimeRange(\n",
    "    start_time=otio.opentime.RationalTime(0, vrate),\n",
    "    duration=otio.opentime.RationalTime(vlength, vrate))\n",
    "\n",
    "    vref = otio.schema.ExternalReference(target_url=vfname,\n",
    "    available_range=v_clip_available_range)\n",
    "\n",
    "\n",
    "#specifying where the start timecode and end timecode of the clip is\n",
    "    v_clip_source_range=otio.opentime.TimeRange(\n",
    "        start_time=otio.opentime.RationalTime(v_clip_starttime, vrate),\n",
    "        duration=otio.opentime.RationalTime(v_clip_duration, vrate))\n",
    "\n",
    "\n",
    "\n",
    "#Video Gaps\n",
    "    #the gap length is equal to (timecode of next clip time - timecode end of previous clip)\n",
    "    v_gap_start_time=0\n",
    "    v_gap_duration=v_clip_starttime-vprevious_end_timecode\n",
    "\n",
    "    v_gap_timerange=otio.opentime.TimeRange(\n",
    "        start_time=otio.opentime.RationalTime(v_gap_start_time, vrate),\n",
    "        duration=otio.opentime.RationalTime(v_gap_duration, vrate))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " #=====================================================   \n",
    "    # adding gaps before adding clips\n",
    "    #convert the tuple ranges from audio rate to video rate\n",
    "        #audio rate=500\n",
    "        #video rate=24\n",
    "\n",
    "\n",
    "\n",
    "    # create gap settings\n",
    "    vgap = otio.schema.Gap(\n",
    "        name=\"vGap{}\".format(i2 + 1),\n",
    "\n",
    "        # available_range_from_list is the \n",
    "        source_range=otio.opentime.TimeRange(\n",
    "            start_time=otio.opentime.RationalTime(\n",
    "                v_gap_timerange.start_time.value,\n",
    "                v_gap_timerange.start_time.rate\n",
    "            ),\n",
    "            duration=otio.opentime.RationalTime(\n",
    "                v_gap_timerange.duration.value,\n",
    "                v_gap_timerange.duration.rate\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # put the clip into the track\n",
    "    vtrack.append(vgap)\n",
    "\n",
    "\n",
    "\n",
    "#=======================================================\n",
    "# adding Video clips \n",
    "#convert the tuple ranges from audio rate to video rate\n",
    "#audio rate=500\n",
    "\n",
    "                #add clip to track                \n",
    "\n",
    "    vcl = otio.schema.Clip(\n",
    "                name=\"vClip{}\".format(i2 + 1),\n",
    "                media_reference=vref,\n",
    "\n",
    "                # available_range_from_list is the \n",
    "                source_range=otio.opentime.TimeRange(\n",
    "                    start_time=otio.opentime.RationalTime(\n",
    "                        v_clip_source_range.start_time.value,\n",
    "                        v_clip_source_range.start_time.rate\n",
    "                    ),\n",
    "                    duration=otio.opentime.RationalTime(\n",
    "                        v_clip_source_range.duration.value,\n",
    "                        v_clip_source_range.duration.rate\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "\n",
    "    vtrack.append(vcl)\n",
    "\n",
    "    vprevious_end_timecode=tuples[1]/arate*vrate\n",
    "    #apreviousduration=\n",
    "\n",
    "\n",
    "\n",
    "    i2=i2+1\n",
    "\n",
    "\n",
    "i=i+1\n",
    "#if i == 2:\n",
    "#break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42f30bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'new_e3_metadata.xml'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otio.adapters.write_to_file(tl, 'e3.kdenlive')\n",
    "otio.adapters.write_to_file(tl, 'new_e3_metadata.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "491eb60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#otio.adapters.write_to_file(tl, 'videoaudio_beta2_main.kdenlive')\n",
    "#otio.adapters.write_to_file(tl, 'videoaudio_beta2_main.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3aed1c",
   "metadata": {},
   "source": [
    "# The clip adding via tuple looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b4cdd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
